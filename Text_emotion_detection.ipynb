{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa156108-edff-4979-b013-75414d9108f5",
   "metadata": {},
   "source": [
    "# Data Preprocessing and model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6168bb47-bcd9-4270-8bf2-12d5e5e948a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label_encoder.joblib']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import re\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import joblib\n",
    "\n",
    "# Load data\n",
    "train = pd.read_table('train.txt', delimiter=\";\", header=None)\n",
    "test = pd.read_table('test.txt', delimiter=\";\", header=None)\n",
    "val = pd.read_table('val.txt', delimiter=\";\", header=None)\n",
    "\n",
    "# Combine data\n",
    "data = pd.concat([train, val, test])\n",
    "data.columns = [\"text\", \"label\"]\n",
    "\n",
    "# Check for missing values\n",
    "data.isna().any(axis=1).sum()\n",
    "\n",
    "# Preprocess function\n",
    "porter = PorterStemmer()\n",
    "def preprocess(line):\n",
    "    review = re.sub(\"[^a-zA-z]\", \" \", line)\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [porter.stem(word) for word in review if not word in stopwords.words(\"english\")]\n",
    "    return \" \".join(review)\n",
    "\n",
    "# Apply preprocessing\n",
    "data[\"text\"] = data[\"text\"].apply(lambda x: preprocess(x))\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "data['emotion'] = label_encoder.fit_transform(data[\"label\"])\n",
    "\n",
    "# Vectorize text\n",
    "cv = CountVectorizer(max_features=5000, ngram_range=(1, 3))\n",
    "data_cv = cv.fit_transform(data[\"text\"]).toarray()\n",
    "\n",
    "# Train-test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_cv, data['emotion'], test_size=0.3, random_state=42)\n",
    "\n",
    "# Save the preprocessed data and label encoder for later use\n",
    "joblib.dump(cv, 'count_vectorizer.joblib')\n",
    "joblib.dump(label_encoder, 'label_encoder.joblib')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96b8fd0-ff7b-41d7-9844-13c5909a4902",
   "metadata": {},
   "source": [
    "# Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "626590b8-b3be-4474-a29b-432933e75f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vishw\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.4717 - loss: 1.3468\n",
      "Epoch 2/10\n",
      "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9085 - loss: 0.3321\n",
      "Epoch 3/10\n",
      "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9561 - loss: 0.1423\n",
      "Epoch 4/10\n",
      "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9744 - loss: 0.0851\n",
      "Epoch 5/10\n",
      "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9863 - loss: 0.0527\n",
      "Epoch 6/10\n",
      "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9900 - loss: 0.0371\n",
      "Epoch 7/10\n",
      "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9918 - loss: 0.0287\n",
      "Epoch 8/10\n",
      "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9915 - loss: 0.0251\n",
      "Epoch 9/10\n",
      "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9936 - loss: 0.0194\n",
      "Epoch 10/10\n",
      "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9950 - loss: 0.0134\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['emotion_detection_model.joblib']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_shape=(x_train.shape[1],), activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=10)\n",
    "\n",
    "# Save the trained model using joblib\n",
    "joblib.dump(model, 'emotion_detection_model.joblib')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71865ad8-5454-4da1-bba3-6f5a476a6a64",
   "metadata": {},
   "source": [
    "# Loading the model and testing with input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdee1b49-874e-4997-bab8-9a788134d2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the saved model, label encoder, and CountVectorizer\n",
    "model = joblib.load('emotion_detection_model.joblib')\n",
    "cv = joblib.load('count_vectorizer.joblib')\n",
    "label_encoder = joblib.load('label_encoder.joblib')\n",
    "\n",
    "# Define preprocessing and prediction function\n",
    "porter = PorterStemmer()\n",
    "def preprocess(line):\n",
    "    review = re.sub(\"[^a-zA-z]\", \" \", line)\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [porter.stem(word) for word in review if not word in stopwords.words(\"english\")]\n",
    "    return \" \".join(review)\n",
    "\n",
    "def predict_emotion(text):\n",
    "    text = preprocess(text)\n",
    "    array = cv.transform([text]).toarray()\n",
    "    pred = model.predict(array)\n",
    "    emotion = label_encoder.inverse_transform(range(pred.shape[1]))\n",
    "    emotion_percentages = {emotion[i]: round(pred[0][i]*100, 2) for i in range(len(emotion))}\n",
    "    return emotion_percentages\n",
    "\n",
    "# Example usage\n",
    "text = \"I am feeling great today!\"\n",
    "emotion_percentages = predict_emotion(text)\n",
    "print(f\"Emotion percentages: {emotion_percentages}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
